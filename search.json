[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "COMP/STAT112 Notebook",
    "section": "",
    "text": "Welcome\nWelcome to my online portfolio for COMP/STAT112 course taken at Macalester College. Please, use the side bar on the left for navigation.",
    "crumbs": [
      "Welcome"
    ]
  },
  {
    "objectID": "bw/bw-uni.html",
    "href": "bw/bw-uni.html",
    "title": "\n1  Univariate Viz\n",
    "section": "",
    "text": "Codelibrary(tidyverse)\n# Importing data\nhikes &lt;- read.csv(\"https://mac-stat.github.io/data/high_peaks.csv\")\n#Graphing relationship between number of hikes and elevation of each\n#| fig-alt: \"Bar graph showing the elevation of different mountain hikes in New York state. Most are in between 4000 and 4500 feet, with only a few as over 5000 and under 3500.\"\nggplot(hikes, aes(x = elevation)) +\n  geom_histogram(color = \"white\", fill = \"pink\", binwidth = 200) +\n  labs(x = \"Elevation (feet)\", y = \"Number of hikes\",\n       title = \"Elevation of Hikes in New York State\",\n       caption = \"Source from Github, Visualization by Colette Lawler\")",
    "crumbs": [
      "Best Work",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Univariate Viz</span>"
    ]
  },
  {
    "objectID": "bw/bw-bi.html",
    "href": "bw/bw-bi.html",
    "title": "\n2  Bivariate Viz\n",
    "section": "",
    "text": "Code# Loading libraries\nlibrary(tidyverse)\n\n\n\nCodeelections &lt;- read.csv(\"https://mac-stat.github.io/data/election_2020_county.csv\")\n# Graphing the relationship between historical and current republican support for US counties in 2020\nggplot(elections, aes(x = repub_pct_20, fill = historical)) +\n  geom_density(alpha = 0.6) +\n  scale_fill_manual(values = c(\"blue\", \"purple\", \"red\")) +\n  labs(x = \"2020 Republican Support\", y = \"Density\",\n       title = \"Relationship between Historical and Current Republican support for US counties in 2020\",\n       caption = \"Source from Github, Visualization by Colette Lawler\")",
    "crumbs": [
      "Best Work",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Bivariate Viz</span>"
    ]
  },
  {
    "objectID": "bw/bw-tri.html",
    "href": "bw/bw-tri.html",
    "title": "\n3  Trivariate Viz\n",
    "section": "",
    "text": "Codelibrary(tidyverse)\nlibrary(mosaic)\n\n\n\nCode#Births per year 1970-1985 per month as trivariable relationship\ndata(\"Birthdays\")\ndaily_births &lt;- Birthdays |&gt; \n  group_by(date) |&gt; \n  summarize(births = sum(births)) |&gt; \n  mutate(year = year(date), \n         month = month(date, label = TRUE),\n         day_of_month = mday(date),\n         day_of_week = wday(date, label = TRUE))\n\n#| fig-alt: \"Scatterplot with trend lines showing number of births per month per year since 1970. Birth rates steadily increase over the years, with later summer months having consistently more births than other months.\"\nggplot(daily_births, aes(y= births, color = month, x = year)) + \n  geom_point() + \n  geom_smooth(method = \"lm\") +\n  labs(x = \"Year\", y = \"Births\", color = \"Month\",\n       title = \"Number of Births per Month per Year since 1970\",\n       caption = \"Source: Mosiac, Visualization: Colette Lawler\")",
    "crumbs": [
      "Best Work",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Trivariate Viz</span>"
    ]
  },
  {
    "objectID": "bw/bw-quad.html",
    "href": "bw/bw-quad.html",
    "title": "\n4  Quadvariate Viz\n",
    "section": "",
    "text": "Codelibrary(tidyverse)\n\n\n\nCode# Import data\nweather &lt;- read.csv(\"https://mac-stat.github.io/data/weather_3_locations.csv\") |&gt; \n  mutate(date = as.Date(date))  \n#Observing the temperature of 3 different locations at 9am, 3pm, and facet wrap seeing if it rained that day\n#| fig-alt: \"Scatterplot showing temperatures at 9am and 3pm in Hobart, Uluru, and Wollongong. Uluru has the highest temperatures consistently. There is a facet wrap showing if it rained the day temperatures were recorded. For days marked yes, the temperature is usually lower in all 3 locations, but not by much.\" \nggplot(weather, aes(y = temp3pm, x = temp9am, color = location)) + \n  geom_point() +\n  facet_wrap(~ raintoday) +\n  labs(x = \"Temp at 9am\", y = \"Temp at 3pm\", color = \"Location\",\n       title = \"Temperature and Rain in 3 locations\",\n       caption = \"Data from Github, Visualization by Colette Lawler\")",
    "crumbs": [
      "Best Work",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Quadvariate Viz</span>"
    ]
  },
  {
    "objectID": "bw/bw-spatial.html",
    "href": "bw/bw-spatial.html",
    "title": "\n5  Spatial Viz\n",
    "section": "",
    "text": "Code#load libraries\nlibrary(tidyverse)\nlibrary(openintro)\nlibrary(sf)\nlibrary(maps)\nlibrary(leaflet)\nlibrary(gplots)\nlibrary(mosaic)\n\n\n\nCode# Import starbucks  data\nstarbucks &lt;- read.csv(\"https://mac-stat.github.io/data/starbucks.csv\")\nstates_map &lt;- map_data(\"state\")\nstarbucks_us_by_state &lt;- starbucks |&gt;\n  filter(Country == \"US\") |&gt;\n  count(State.Province) |&gt;\n  mutate(state_name = str_to_lower(abbr2state(State.Province)))\ncensus_pop_est_2018 &lt;- read_csv(\"https://mac-stat.github.io/data/us_census_2018_state_pop_est.csv\") |&gt;\n  separate(state, into = c(\"dot\", \"state\"), extra = \"merge\") |&gt;\n  select(-dot) |&gt;\n  mutate(state = str_to_lower(state))\nstarbucks_with_2018_pop_est &lt;-\n  starbucks_us_by_state |&gt;\n  left_join(census_pop_est_2018,\n    by = c(\"state_name\" = \"state\")\n  ) |&gt;\n  mutate(starbucks_per_10000 = (n / est_pop_2018) * 10000)\nstarbucks_contiguous_us &lt;- starbucks |&gt;\n  filter(Country == \"US\", State.Province != \"AK\", State.Province != \"HI\")\n\n#Creating map of Starbucks locations, and density of Starbucks per population\n#| fig-alt: \"Map of Starbucks locations in the United States. Most are concentrated on the West Coast, with a lot existing in major cities across the US. The least amount of Starbucks are in the South.\"\nggplot(starbucks_with_2018_pop_est) +\n  geom_map(map = states_map, aes(map_id = state_name, fill = starbucks_per_10000)) +\n  expand_limits(x = states_map$long, y = states_map$lat) +\n  theme_map() +\n  scale_fill_gradientn(name = \"Starbucks Per 10000 People\", colors = c(\"darkgreen\", \"green\", \"lightgreen\"), values = scales::rescale(seq(0, 100, by = 5))) +\n  geom_point(\n    data = starbucks_contiguous_us,\n    aes(x = Longitude, y = Latitude),\n    alpha = 0.3, size = 0.2, color = \"blue\"\n  ) +\n  theme_map() +\n  labs(title = \"Density of Starbucks' in the United States\", \n       caption = \"Source from Github, By Colette Lawler\")",
    "crumbs": [
      "Best Work",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Spatial Viz</span>"
    ]
  },
  {
    "objectID": "bw/exam.html",
    "href": "bw/exam.html",
    "title": "\n6  Exam 1\n",
    "section": "",
    "text": "Codelibrary(tidytuesdayR)\nlibrary(tidyverse)\n\ntuesdata &lt;- tt_load('2020-02-18')\nfc &lt;- tuesdata$food_consumption\n\n\n\nCodeworld_map &lt;- map_data(\"world\")\n\n#| fig-cap: \"10 maps of the world with food consumption in kilograms per person per year for food categories of beef, eggs, fish, lamb and goat, milk, nuts, pork, poultry, rice, soybeans, and wheat. Milk and wheat has the most overall consumption in the world.\" \n\nggplot(fc, aes(map_id = country, fill = consumption)) +\n  geom_map(map = world_map) +\n  expand_limits(x = world_map$long, y = world_map$lat) +\n  facet_wrap(~food_category) +\n  labs(x = \"\", y = \"\",\n       title = \"Food Consumption per Country by Food Category\",\n       caption = \"Source: Tidy Tuesday, Visualization by Colette Lawler\") +\n  scale_fill_gradientn(name = \"Consumption: kg/person/year\", colors = c(\"lightblue\", \"blue\", \"darkblue\"))",
    "crumbs": [
      "Best Work",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Exam 1</span>"
    ]
  },
  {
    "objectID": "bw/exam_2.html",
    "href": "bw/exam_2.html",
    "title": "\n7  Exam 2\n",
    "section": "",
    "text": "Codelibrary(tidytuesdayR)\nlibrary(tidyverse)\nlibrary(rnaturalearth) \nlibrary(sf)\n\ntuesdata &lt;- tt_load('2020-02-18')\nfc &lt;- tuesdata$food_consumption\n\nstr(fc)\n\nspc_tbl_ [1,430 × 4] (S3: spec_tbl_df/tbl_df/tbl/data.frame)\n $ country      : chr [1:1430] \"Argentina\" \"Argentina\" \"Argentina\" \"Argentina\" ...\n $ food_category: chr [1:1430] \"Pork\" \"Poultry\" \"Beef\" \"Lamb & Goat\" ...\n $ consumption  : num [1:1430] 10.51 38.66 55.48 1.56 4.36 ...\n $ co2_emmission: num [1:1430] 37.2 41.53 1712 54.63 6.96 ...\n - attr(*, \"spec\")=\n  .. cols(\n  ..   country = col_character(),\n  ..   food_category = col_character(),\n  ..   consumption = col_double(),\n  ..   co2_emmission = col_double()\n  .. )\n - attr(*, \"problems\")=&lt;externalptr&gt; \n\nCodehead(fc, 22)\n\n# A tibble: 22 × 4\n   country   food_category            consumption co2_emmission\n   &lt;chr&gt;     &lt;chr&gt;                          &lt;dbl&gt;         &lt;dbl&gt;\n 1 Argentina Pork                           10.5          37.2 \n 2 Argentina Poultry                        38.7          41.5 \n 3 Argentina Beef                           55.5        1712   \n 4 Argentina Lamb & Goat                     1.56         54.6 \n 5 Argentina Fish                            4.36          6.96\n 6 Argentina Eggs                           11.4          10.5 \n 7 Argentina Milk - inc. cheese            195.          278.  \n 8 Argentina Wheat and Wheat Products      103.           19.7 \n 9 Argentina Rice                            8.77         11.2 \n10 Argentina Soybeans                        0             0   \n# ℹ 12 more rows\n\n\n\nCodefcc &lt;-\nfc |&gt;\n  mutate(food_category = fct_recode(food_category, \n         \"Lamb\" = \"Lamb & Goat\",\n         \"Dairy\" = \"Milk - inc. cheese\",\n         \"Wheat\" = \"Wheat and Wheat Products\", \n         \"Nuts\" = \"Nuts inc. Peanut Butter\"\n                          )) \n\n\n\nWhich 5 countries consume the most food?\n\n\nCodefcc |&gt;\n  group_by(country) |&gt;\n  summarize(sum = sum(consumption)) |&gt;\n  arrange(desc(sum)) |&gt;\n  head(5)\n\n# A tibble: 5 × 2\n  country       sum\n  &lt;chr&gt;       &lt;dbl&gt;\n1 Finland      640.\n2 Lithuania    555.\n3 Sweden       550 \n4 Netherlands  534.\n5 Albania      533.\n\n\n\nCodefc |&gt;\n  group_by(country) |&gt;\n  summarize(sum = sum(consumption)) |&gt;\n  arrange(desc(sum)) |&gt;\n  head(5) |&gt;\nggplot(aes(x = country, y = sum)) +\n  geom_col() +\n  labs(x = \"Country\", y = \"Food Consumption\")\n\n\n\n\n\n\n\n\nWhich top 5 countries consume each food?\n\n\nCodefc |&gt;\n  select(food_category, country, consumption) |&gt;\n   group_by(food_category) |&gt;\n  slice_max(consumption, n = 5)\n\n# A tibble: 55 × 3\n# Groups:   food_category [11]\n   food_category country   consumption\n   &lt;chr&gt;         &lt;chr&gt;           &lt;dbl&gt;\n 1 Beef          Argentina        55.5\n 2 Beef          Brazil           39.2\n 3 Beef          USA              36.2\n 4 Beef          Australia        33.9\n 5 Beef          Bermuda          33.2\n 6 Eggs          Japan            19.2\n 7 Eggs          Paraguay         18.8\n 8 Eggs          China            18.8\n 9 Eggs          Mexico           18.3\n10 Eggs          Ukraine          18.0\n# ℹ 45 more rows\n\n\n\nCodefc |&gt;\n  select(food_category, country, consumption) |&gt;\n  group_by(food_category) |&gt;\n  slice_max(consumption, n = 5) |&gt;\nggplot(aes(x = country, y = consumption)) +\ngeom_col() +\n  facet_wrap(~food_category) +\n  labs(x = \"Country\", y = \"Consumption\")\n\n\n\n\n\n\n\n\nWhat does the consumption of each food look like?\n\n\nCodene_countries(returnclass = \"sf\") |&gt;\n  select(name, geometry) |&gt;\n  mutate(name = ifelse(name == \"United States of America\", \"USA\", name)) |&gt;\n  mutate(name = ifelse(name == \"Bosnia and Herz.\", \"Bosnia and Herzegovina\", name)) |&gt;\n  mutate(name = ifelse(name == \"Czechia\", \"Czech Republic\", name)) |&gt; \n  mutate(name = ifelse(name == \"Taiwan\", \"Taiwan. ROC\", name)) |&gt;\n  left_join(\n    fcc |&gt;\n      select(-co2_emmission) |&gt;\n      group_by(food_category) |&gt;\n      mutate(consumption = (consumption - mean(consumption))/sd(consumption)),\n    by = c(\"name\" = \"country\")\n  ) |&gt;\n  pivot_wider(names_from = food_category, values_from = consumption) |&gt;\n  select(-\"NA\") |&gt;  \n  pivot_longer(cols = c(-name, -geometry), names_to = \"food_category\", values_to = \"consumption\") |&gt;\n  ggplot() +\n  geom_sf(aes(fill = consumption), color = \"black\", size = 0.2) +  \n  scale_fill_viridis_c(option = \"B\", direction = 1, na.value = \"gray\") +  \n  facet_wrap(~food_category) +\n  labs(\n    title = \"Food Consumption by Country\",\n    fill = \"Consumption\",\n    caption = \"Visualization by Colette Lawler\"\n  ) +\n  theme_minimal() +\n  theme(legend.position = \"bottom\",\n        strip.text = element_text(size = 10),\n        panel.spacing = unit(1, \"lines\"))\n\n\n\n\n\n\n\n::: {.cell}\n\n:::\n\n\n\n\n\n:::{#quarto-navigation-envelope .hidden}\n[Colette Lawler]{.hidden .quarto-markdown-envelope-contents render-id=\"quarto-int-sidebar-title\"}\n[COMP/STAT112 Notebook]{.hidden .quarto-markdown-envelope-contents render-id=\"quarto-int-navbar-title\"}\n[&lt;span class='chapter-number'&gt;8&lt;/span&gt;  &lt;span class='chapter-title'&gt;solo.project&lt;/span&gt;]{.hidden .quarto-markdown-envelope-contents render-id=\"quarto-int-next\"}\n[&lt;span class='chapter-number'&gt;6&lt;/span&gt;  &lt;span class='chapter-title'&gt;Exam 1&lt;/span&gt;]{.hidden .quarto-markdown-envelope-contents render-id=\"quarto-int-prev\"}\n[Welcome]{.hidden .quarto-markdown-envelope-contents render-id=\"quarto-int-sidebar:/index.htmlWelcome\"}\n[Best Work]{.hidden .quarto-markdown-envelope-contents render-id=\"quarto-int-sidebar:quarto-sidebar-section-1\"}\n[&lt;span class='chapter-number'&gt;1&lt;/span&gt;  &lt;span class='chapter-title'&gt;Univariate Viz&lt;/span&gt;]{.hidden .quarto-markdown-envelope-contents render-id=\"quarto-int-sidebar:/bw/bw-uni.html&lt;span-class='chapter-number'&gt;1&lt;/span&gt;--&lt;span-class='chapter-title'&gt;Univariate-Viz&lt;/span&gt;\"}\n[&lt;span class='chapter-number'&gt;2&lt;/span&gt;  &lt;span class='chapter-title'&gt;Bivariate Viz&lt;/span&gt;]{.hidden .quarto-markdown-envelope-contents render-id=\"quarto-int-sidebar:/bw/bw-bi.html&lt;span-class='chapter-number'&gt;2&lt;/span&gt;--&lt;span-class='chapter-title'&gt;Bivariate-Viz&lt;/span&gt;\"}\n[&lt;span class='chapter-number'&gt;3&lt;/span&gt;  &lt;span class='chapter-title'&gt;Trivariate Viz&lt;/span&gt;]{.hidden .quarto-markdown-envelope-contents render-id=\"quarto-int-sidebar:/bw/bw-tri.html&lt;span-class='chapter-number'&gt;3&lt;/span&gt;--&lt;span-class='chapter-title'&gt;Trivariate-Viz&lt;/span&gt;\"}\n[&lt;span class='chapter-number'&gt;4&lt;/span&gt;  &lt;span class='chapter-title'&gt;Quadvariate Viz&lt;/span&gt;]{.hidden .quarto-markdown-envelope-contents render-id=\"quarto-int-sidebar:/bw/bw-quad.html&lt;span-class='chapter-number'&gt;4&lt;/span&gt;--&lt;span-class='chapter-title'&gt;Quadvariate-Viz&lt;/span&gt;\"}\n[&lt;span class='chapter-number'&gt;5&lt;/span&gt;  &lt;span class='chapter-title'&gt;Spatial Viz&lt;/span&gt;]{.hidden .quarto-markdown-envelope-contents render-id=\"quarto-int-sidebar:/bw/bw-spatial.html&lt;span-class='chapter-number'&gt;5&lt;/span&gt;--&lt;span-class='chapter-title'&gt;Spatial-Viz&lt;/span&gt;\"}\n[&lt;span class='chapter-number'&gt;6&lt;/span&gt;  &lt;span class='chapter-title'&gt;Exam 1&lt;/span&gt;]{.hidden .quarto-markdown-envelope-contents render-id=\"quarto-int-sidebar:/bw/exam.html&lt;span-class='chapter-number'&gt;6&lt;/span&gt;--&lt;span-class='chapter-title'&gt;Exam-1&lt;/span&gt;\"}\n[&lt;span class='chapter-number'&gt;7&lt;/span&gt;  &lt;span class='chapter-title'&gt;Exam 2&lt;/span&gt;]{.hidden .quarto-markdown-envelope-contents render-id=\"quarto-int-sidebar:/bw/exam_2.html&lt;span-class='chapter-number'&gt;7&lt;/span&gt;--&lt;span-class='chapter-title'&gt;Exam-2&lt;/span&gt;\"}\n[&lt;span class='chapter-number'&gt;8&lt;/span&gt;  &lt;span class='chapter-title'&gt;solo.project&lt;/span&gt;]{.hidden .quarto-markdown-envelope-contents render-id=\"quarto-int-sidebar:/bw/soloproj.html&lt;span-class='chapter-number'&gt;8&lt;/span&gt;--&lt;span-class='chapter-title'&gt;solo.project&lt;/span&gt;\"}\n[Summary Sheets]{.hidden .quarto-markdown-envelope-contents render-id=\"quarto-int-sidebar:quarto-sidebar-section-2\"}\n[&lt;span class='chapter-number'&gt;9&lt;/span&gt;  &lt;span class='chapter-title'&gt;Visualization&lt;/span&gt;]{.hidden .quarto-markdown-envelope-contents render-id=\"quarto-int-sidebar:/summaries/Visualization.html&lt;span-class='chapter-number'&gt;9&lt;/span&gt;--&lt;span-class='chapter-title'&gt;Visualization&lt;/span&gt;\"}\n[&lt;span class='chapter-number'&gt;10&lt;/span&gt;  &lt;span class='chapter-title'&gt;Wrangling&lt;/span&gt;]{.hidden .quarto-markdown-envelope-contents render-id=\"quarto-int-sidebar:/summaries/Wranging.html&lt;span-class='chapter-number'&gt;10&lt;/span&gt;--&lt;span-class='chapter-title'&gt;Wrangling&lt;/span&gt;\"}\n[In-class Activities]{.hidden .quarto-markdown-envelope-contents render-id=\"quarto-int-sidebar:quarto-sidebar-section-3\"}\n[&lt;span class='chapter-number'&gt;11&lt;/span&gt;  &lt;span class='chapter-title'&gt;Univariate Viz&lt;/span&gt;]{.hidden .quarto-markdown-envelope-contents render-id=\"quarto-int-sidebar:/ica/ica-uni.html&lt;span-class='chapter-number'&gt;11&lt;/span&gt;--&lt;span-class='chapter-title'&gt;Univariate-Viz&lt;/span&gt;\"}\n[&lt;span class='chapter-number'&gt;12&lt;/span&gt;  &lt;span class='chapter-title'&gt;Bivariate Viz&lt;/span&gt;]{.hidden .quarto-markdown-envelope-contents render-id=\"quarto-int-sidebar:/ica/ica-bi.html&lt;span-class='chapter-number'&gt;12&lt;/span&gt;--&lt;span-class='chapter-title'&gt;Bivariate-Viz&lt;/span&gt;\"}\n[&lt;span class='chapter-number'&gt;13&lt;/span&gt;  &lt;span class='chapter-title'&gt;Mulivariate Viz&lt;/span&gt;]{.hidden .quarto-markdown-envelope-contents render-id=\"quarto-int-sidebar:/ica/ica-multi.html&lt;span-class='chapter-number'&gt;13&lt;/span&gt;--&lt;span-class='chapter-title'&gt;Mulivariate-Viz&lt;/span&gt;\"}\n[&lt;span class='chapter-number'&gt;14&lt;/span&gt;  &lt;span class='chapter-title'&gt;Spatial Viz&lt;/span&gt;]{.hidden .quarto-markdown-envelope-contents render-id=\"quarto-int-sidebar:/ica/ica-spatial.html&lt;span-class='chapter-number'&gt;14&lt;/span&gt;--&lt;span-class='chapter-title'&gt;Spatial-Viz&lt;/span&gt;\"}\n[Best Work]{.hidden .quarto-markdown-envelope-contents render-id=\"quarto-breadcrumbs-Best-Work\"}\n[&lt;span class='chapter-number'&gt;7&lt;/span&gt;  &lt;span class='chapter-title'&gt;Exam 2&lt;/span&gt;]{.hidden .quarto-markdown-envelope-contents render-id=\"quarto-breadcrumbs-&lt;span-class='chapter-number'&gt;7&lt;/span&gt;--&lt;span-class='chapter-title'&gt;Exam-2&lt;/span&gt;\"}\n:::\n\n\n\n:::{#quarto-meta-markdown .hidden}\n[[7]{.chapter-number}  [Exam 2]{.chapter-title} – COMP/STAT112 Notebook]{.hidden .quarto-markdown-envelope-contents render-id=\"quarto-metatitle\"}\n[[7]{.chapter-number}  [Exam 2]{.chapter-title} – COMP/STAT112 Notebook]{.hidden .quarto-markdown-envelope-contents render-id=\"quarto-twittercardtitle\"}\n[[7]{.chapter-number}  [Exam 2]{.chapter-title} – COMP/STAT112 Notebook]{.hidden .quarto-markdown-envelope-contents render-id=\"quarto-ogcardtitle\"}\n[COMP/STAT112 Notebook]{.hidden .quarto-markdown-envelope-contents render-id=\"quarto-metasitename\"}\n[]{.hidden .quarto-markdown-envelope-contents render-id=\"quarto-twittercarddesc\"}\n[]{.hidden .quarto-markdown-envelope-contents render-id=\"quarto-ogcardddesc\"}\n:::\n\n\n\n\n&lt;!-- --&gt;\n\n::: {.quarto-embedded-source-code}\n```````````````````{.markdown shortcodes=\"false\"}\n---\ntitle: \"Exam 2\"\nformat: html\n---\n\nquarto-executable-code-5450563D\n\n```r\nlibrary(tidytuesdayR)\nlibrary(tidyverse)\nlibrary(rnaturalearth) \nlibrary(sf)\n\ntuesdata &lt;- tt_load('2020-02-18')\nfc &lt;- tuesdata$food_consumption\n\nstr(fc)\n\nhead(fc, 22)\nquarto-executable-code-5450563D\nfcc &lt;-\nfc |&gt;\n  mutate(food_category = fct_recode(food_category, \n         \"Lamb\" = \"Lamb & Goat\",\n         \"Dairy\" = \"Milk - inc. cheese\",\n         \"Wheat\" = \"Wheat and Wheat Products\", \n         \"Nuts\" = \"Nuts inc. Peanut Butter\"\n                          )) \n\nWhich 5 countries consume the most food?\n\nquarto-executable-code-5450563D\nfcc |&gt;\n  group_by(country) |&gt;\n  summarize(sum = sum(consumption)) |&gt;\n  arrange(desc(sum)) |&gt;\n  head(5)\nquarto-executable-code-5450563D\nfc |&gt;\n  group_by(country) |&gt;\n  summarize(sum = sum(consumption)) |&gt;\n  arrange(desc(sum)) |&gt;\n  head(5) |&gt;\nggplot(aes(x = country, y = sum)) +\n  geom_col() +\n  labs(x = \"Country\", y = \"Food Consumption\")\n\nWhich top 5 countries consume each food?\n\nquarto-executable-code-5450563D\nfc |&gt;\n  select(food_category, country, consumption) |&gt;\n   group_by(food_category) |&gt;\n  slice_max(consumption, n = 5)\nquarto-executable-code-5450563D\nfc |&gt;\n  select(food_category, country, consumption) |&gt;\n  group_by(food_category) |&gt;\n  slice_max(consumption, n = 5) |&gt;\nggplot(aes(x = country, y = consumption)) +\ngeom_col() +\n  facet_wrap(~food_category) +\n  labs(x = \"Country\", y = \"Consumption\")\n\nWhat does the consumption of each food look like?\n\nquarto-executable-code-5450563D\nne_countries(returnclass = \"sf\") |&gt;\n  select(name, geometry) |&gt;\n  mutate(name = ifelse(name == \"United States of America\", \"USA\", name)) |&gt;\n  mutate(name = ifelse(name == \"Bosnia and Herz.\", \"Bosnia and Herzegovina\", name)) |&gt;\n  mutate(name = ifelse(name == \"Czechia\", \"Czech Republic\", name)) |&gt; \n  mutate(name = ifelse(name == \"Taiwan\", \"Taiwan. ROC\", name)) |&gt;\n  left_join(\n    fcc |&gt;\n      select(-co2_emmission) |&gt;\n      group_by(food_category) |&gt;\n      mutate(consumption = (consumption - mean(consumption))/sd(consumption)),\n    by = c(\"name\" = \"country\")\n  ) |&gt;\n  pivot_wider(names_from = food_category, values_from = consumption) |&gt;\n  select(-\"NA\") |&gt;  \n  pivot_longer(cols = c(-name, -geometry), names_to = \"food_category\", values_to = \"consumption\") |&gt;\n  ggplot() +\n  geom_sf(aes(fill = consumption), color = \"black\", size = 0.2) +  \n  scale_fill_viridis_c(option = \"B\", direction = 1, na.value = \"gray\") +  \n  facet_wrap(~food_category) +\n  labs(\n    title = \"Food Consumption by Country\",\n    fill = \"Consumption\",\n    caption = \"Visualization by Colette Lawler\"\n  ) +\n  theme_minimal() +\n  theme(legend.position = \"bottom\",\n        strip.text = element_text(size = 10),\n        panel.spacing = unit(1, \"lines\"))\nquarto-executable-code-5450563D\n\n```r\n``````````````````` :::",
    "crumbs": [
      "Best Work",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Exam 2</span>"
    ]
  },
  {
    "objectID": "bw/soloproj.html",
    "href": "bw/soloproj.html",
    "title": "\n8  solo.project\n",
    "section": "",
    "text": "Codelibrary(sf)\ncounty_shapes &lt;- read_sf(\"/Users/colettelawler/Downloads/cb_2023_us_county_500k\")\n\nhead(county_shapes)\n\nSimple feature collection with 6 features and 12 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: -94.47732 ymin: 30.22333 xmax: -84.99943 ymax: 34.19253\nGeodetic CRS:  NAD83\n# A tibble: 6 × 13\n  STATEFP COUNTYFP COUNTYNS GEOIDFQ GEOID NAME  NAMELSAD STUSPS STATE_NAME LSAD \n  &lt;chr&gt;   &lt;chr&gt;    &lt;chr&gt;    &lt;chr&gt;   &lt;chr&gt; &lt;chr&gt; &lt;chr&gt;    &lt;chr&gt;  &lt;chr&gt;      &lt;chr&gt;\n1 01      003      00161527 050000… 01003 Bald… Baldwin… AL     Alabama    06   \n2 01      069      00161560 050000… 01069 Hous… Houston… AL     Alabama    06   \n3 01      005      00161528 050000… 01005 Barb… Barbour… AL     Alabama    06   \n4 01      119      00161585 050000… 01119 Sumt… Sumter … AL     Alabama    06   \n5 05      091      00069166 050000… 05091 Mill… Miller … AR     Arkansas   06   \n6 05      133      00069182 050000… 05133 Sevi… Sevier … AR     Arkansas   06   \n# ℹ 3 more variables: ALAND &lt;dbl&gt;, AWATER &lt;dbl&gt;, geometry &lt;MULTIPOLYGON [°]&gt;\n\n\n\nCodelibrary(tidyverse) \n  vaccine_data &lt;- read_csv(\"/Users/colettelawler/Downloads/Vaccine_Hesitancy_for_COVID-19__County_and_local_estimates_20250402.csv\")\n\n\n\nCodehead(vaccine_data)\n\n# A tibble: 6 × 21\n  `FIPS Code` `County Name`    State `Estimated hesitant` Estimated hesitant o…¹\n        &lt;dbl&gt; &lt;chr&gt;            &lt;chr&gt;                &lt;dbl&gt;                  &lt;dbl&gt;\n1        1123 Tallapoosa Coun… ALAB…                0.181                  0.24 \n2        1121 Talladega Count… ALAB…                0.178                  0.235\n3        1131 Wilcox County, … ALAB…                0.174                  0.236\n4        1129 Washington Coun… ALAB…                0.174                  0.236\n5        1119 Sumter County, … ALAB…                0.181                  0.253\n6        1133 Winston County,… ALAB…                0.180                  0.231\n# ℹ abbreviated name: ¹​`Estimated hesitant or unsure`\n# ℹ 16 more variables: `Estimated strongly hesitant` &lt;dbl&gt;,\n#   `Social Vulnerability Index (SVI)` &lt;dbl&gt;, `SVI Category` &lt;chr&gt;,\n#   `CVAC level of concern for vaccination rollout` &lt;dbl&gt;,\n#   `CVAC Level Of Concern` &lt;chr&gt;,\n#   `Percent adults fully vaccinated against COVID-19 (as of 6/10/21)` &lt;dbl&gt;,\n#   `Percent Hispanic` &lt;dbl&gt;, …\n\n\n\nCodevaccine_clean &lt;-\nvaccine_data |&gt;\n  filter(State == \"NEBRASKA\") |&gt;\n  separate(`County Name`, c(\"name\", \"county\")) \n\n\n\nCodevaccine_renamed &lt;-\nvaccine_clean |&gt;\n  rename(estimated_hesitant = \"Estimated hesitant\") |&gt;\n  rename(estimated_hesitant_or_unsure = \"Estimated hesitant or unsure\") |&gt;\n  rename(estimated_strongly_hesitant = \"Estimated strongly hesitant\") |&gt;\n  mutate(total_hesitancy = estimated_hesitant_or_unsure + estimated_strongly_hesitant + estimated_hesitant) |&gt;\n  filter(State == \"NEBRASKA\") |&gt;\n  select(name, total_hesitancy)\n\nhead(vaccine_renamed)\n\n# A tibble: 6 × 2\n  name     total_hesitancy\n  &lt;chr&gt;              &lt;dbl&gt;\n1 Gage               0.28 \n2 Cherry             0.264\n3 Dundy              0.272\n4 Cheyenne           0.264\n5 Seward             0.28 \n6 Thayer             0.28 \n\n\n\nCodenebraska_shapes &lt;-\n  county_shapes |&gt;\n  filter(STATE_NAME == \"Nebraska\")\n\nhead(nebraska_shapes)\n\nSimple feature collection with 6 features and 12 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: -103.3825 ymin: 40.00184 xmax: -97.36812 ymax: 42.0092\nGeodetic CRS:  NAD83\n# A tibble: 6 × 13\n  STATEFP COUNTYFP COUNTYNS GEOIDFQ GEOID NAME  NAMELSAD STUSPS STATE_NAME LSAD \n  &lt;chr&gt;   &lt;chr&gt;    &lt;chr&gt;    &lt;chr&gt;   &lt;chr&gt; &lt;chr&gt; &lt;chr&gt;    &lt;chr&gt;  &lt;chr&gt;      &lt;chr&gt;\n1 31      033      00835838 050000… 31033 Chey… Cheyenn… NE     Nebraska   06   \n2 31      049      00835846 050000… 31049 Deuel Deuel C… NE     Nebraska   06   \n3 31      185      00835914 050000… 31185 York  York Co… NE     Nebraska   06   \n4 31      005      00835825 050000… 31005 Arth… Arthur … NE     Nebraska   06   \n5 31      169      00835906 050000… 31169 Thay… Thayer … NE     Nebraska   06   \n6 31      069      00835856 050000… 31069 Gard… Garden … NE     Nebraska   06   \n# ℹ 3 more variables: ALAND &lt;dbl&gt;, AWATER &lt;dbl&gt;, geometry &lt;MULTIPOLYGON [°]&gt;\n\nCodenebraska_shapes &lt;-\n  nebraska_shapes |&gt;\n  full_join(vaccine_renamed, join_by(NAME == name))\n\n\n\nCodeggplot() +\n  geom_sf(data = nebraska_shapes,\n          aes(fill = total_hesitancy)) +\n   scale_fill_gradientn(name = \"Total Hesitancy\", colors = terrain.colors(10)) +\n  labs(fill = NULL,\n       title = \"Percentage of population per country hesitant to receive COVID-19 vaccine in Nebraska\",\n       caption = \"Source: CDC • Visualization by Colette Lawler\") +\n  theme_void() +\n  theme(legend.position = \"right\")\n\n\n\n\n\n\n\nThis map shows percentages of vaccine hesitancy per county in Nebraska. There are a few counties with N/A data, but for the most part, there’s medium hesitancy in general. Honestly, from living in Nebraska and experiencing the political climate of the state, it’s a lot less than I expected. In Eastern Nebraska (the green counties represent Omaha and Lincoln), it doesn’t surprise me that there’s less hesitancy, since those counties tend to lean more Democratic than rural counties, which heavily favor Republicans (many of whom, especially in Nebraska, were opposed to vaccine and mask mandates).",
    "crumbs": [
      "Best Work",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>solo.project</span>"
    ]
  },
  {
    "objectID": "ica/ica-uni.html",
    "href": "ica/ica-uni.html",
    "title": "\n11  Univariate Viz\n",
    "section": "",
    "text": "Use this file for practice with the univariate viz in-class activity. Refer to the class website for details.\n\nCode# Import data\nhikes &lt;- read.csv(\"https://mac-stat.github.io/data/high_peaks.csv\")\n\n\n\nCodehead(hikes)\n\n             peak elevation difficulty ascent length time    rating\n1     Mt. Marcy        5344          5   3166   14.8 10.0  moderate\n2 Algonquin Peak       5114          5   2936    9.6  9.0  moderate\n3   Mt. Haystack       4960          7   3570   17.8 12.0 difficult\n4   Mt. Skylight       4926          7   4265   17.9 15.0 difficult\n5 Whiteface Mtn.       4867          4   2535   10.4  8.5      easy\n6       Dix Mtn.       4857          5   2800   13.2 10.0  moderate\n\n\n\neasiest to hardest progression\nlow to high elevation\n\n\nCode# Load the package\nlibrary(tidyverse)\n\n\n\nCodeggplot(hikes, aes(x = rating))\n\n\n\n\n\n\n\n\nCode# + geom_bar(), adds bar graph about each rating \nggplot(hikes, aes(x = rating)) +\n  geom_bar()\n\n\n\n\n\n\n\n\nCode# adds a lab about the y axis, labels the y as number of hikes\nggplot(hikes, aes(x = rating)) +\n  geom_bar() +\n  labs(x = \"Rating\", y = \"Number of hikes\")\n\n\n\n\n\n\n\n\nCode# has the bar filled as \"blue\", changes bars to blue color\nggplot(hikes, aes(x = rating)) +\n  geom_bar(fill = \"blue\") +\n  labs(x = \"Rating\", y = \"Number of hikes\")\n\n\n\n\n\n\n\n\nCode# has the color and fill differently in geom_bar, outlines bar orange\nggplot(hikes, aes(x = rating)) +\n  geom_bar(color = \"orange\", fill = \"blue\") +\n  labs(x = \"Rating\", y = \"Number of hikes\")\n\n\n\n\n\n\n\n\nCode# adds a theme_minimal(), removes the background shading\nggplot(hikes, aes(x = rating)) +\n  geom_bar(color = \"orange\", fill = \"blue\")  +\n  labs(x = \"Rating\", y = \"Number of hikes\") +\n  theme_minimal()\n\n\n\n\n\n\n\n\nWhat’s the purpose of the +? When do we use it? Adding more visual features to the graph, when we want to make data look a certain way\nWe added the bars using geom_bar()? Why “geom”? It’s a layer, a geometric element\nWhat does labs() stand for? Each axis\nWhat’s the difference between color and fill? Color is outline, fill is bar itself\nobserved categories: What categories did we observe? number of hikes, ratings\nvariability between categories: Are observations evenly spread out among the categories, or are some categories more common than others? moderates hikes are the most common\nIs there anything you don’t like about this barplot? For example: check out the x-axis again. it doesn’t go easy &gt; medium &gt; hard\n\n\nCodeggplot(hikes, aes(x = elevation)) +\n  geom_bar()\n\n\n\n\n\n\n\n\nExplain why this might not be an effective visualization for this and other quantitative variables. (What questions does / doesn’t it help answer?) It doesn’t make a nice chart to answer a typical elevation, also there are too many data points for a bar graph so it doesn’t look as nice\nHow many hikes have an elevation between 4500 and 4700 feet? around 6\nHow many total hikes have an elevation of at least 5100 feet? around 4\ntypical outcome: Where’s the center of the data points? What’s typical? around 4000 feet\nvariability & range: How spread out are the outcomes? What are the max and min outcomes? pretty spread out, lowest is around 3800 and highest is 5500\nshape: How are values distributed along the observed range? Is the distribution symmetric, right-skewed, left-skewed, bi-modal, or uniform (flat)? more left-skewed\noutliers: Are there any outliers, i.e. outcomes that are unusually large/small? not really\nAddressing each of the features in the above list, summarize below what you learned from the histogram, in context. Most hikes have an elevation around 4000ft or a bit more, there are less hikes the higher elevation you get around 4500\n\n\nCode# adds a geom_histogram(), adds larger bars on each data point\nggplot(hikes, aes(x = elevation)) +\n  geom_histogram()\n\n\n\n\n\n\n\n\nCode# adds a color to the histogram, outlines in white\nggplot(hikes, aes(x = elevation)) +\n  geom_histogram(color = \"white\") \n\n\n\n\n\n\n\n\nCode# adds a fill, makes the bars blue with white outline\nggplot(hikes, aes(x = elevation)) +\n  geom_histogram(color = \"white\", fill = \"blue\") \n\n\n\n\n\n\n\n\nCode# adds a lab(), labels x and y axis\nggplot(hikes, aes(x = elevation)) +\n  geom_histogram(color = \"white\") +\n  labs(x = \"Elevation (feet)\", y = \"Number of hikes\")\n\n\n\n\n\n\n\n\nCode# adds binwidth, changes the range of the data, makes each bar into multiple hikes\nggplot(hikes, aes(x = elevation)) +\n  geom_histogram(color = \"white\", fill = \"pink\", binwidth = 200) +\n  labs(x = \"Elevation (feet)\", y = \"Number of hikes\")\n\n\n\n\n\n\n\n\nCode# chnages binwidth to 5, changes y axis to smaller intervals\nggplot(hikes, aes(x = elevation)) +\n  geom_histogram(color = \"white\", binwidth = 5) +\n  labs(x = \"Elevation (feet)\", y = \"Number of hikes\")\n\n\n\n\n\n\n\n\nCode# changes binwidth to 200, again changes y-axis interval\nggplot(hikes, aes(x = elevation)) +\n  geom_histogram(color = \"white\", binwidth = 200) +\n  labs(x = \"Elevation (feet)\", y = \"Number of hikes\")\n\n\n\n\n\n\n\n\nWhat function added the histogram layer / geometry? geom_histogram()\nWhat’s the difference between color and fill? color is an outline, fill is the actual color of the bar\nWhy does adding color = “white” improve the visualization? it makes the divides between the bars easier to see\nWhat did binwidth do? changes the y-axis interval\nWhy does the histogram become ineffective if the binwidth is too big (e.g. 1000 feet)? there’s too many data points clumped in the bar\nWhy does the histogram become ineffective if the binwidth is too small (e.g. 5 feet)? it makes too many lines and becomes distractig\n\n\nCodeggplot(hikes, aes(x = elevation)) +\n  geom_density() + \n  geom_density(fill = \"orange\")\n\n\n\n\n\n\n\nINTUITION CHECK: Before tweaking the code and thinking back to geom_bar() and geom_histogram(), how do you anticipate the following code will change the plot?\ngeom_density(color = “blue”) make the line outlined blue geom_density(fill = “orange”) make the line blue TRY IT! Test out those lines in the chunk below. Was your intuition correct?\nExamine the density plot. How does it compare to the histogram? What does it tell you about the typical elevation, variability / range in elevations, and shape of the distribution of elevations within this range? clearly says where it peaks, and this distribution/shape of data, seems more effective\n\nThe histogram and density plot both allow us to visualize the behavior of a quantitative variable: typical outcome, variability / range, shape, and outliers. What are the pros/cons of each? What do you like/not like about each? bar graph makes it easy to have better visuals and colors, and can show clear outliers, but the density plot makes for easier data observations about averages\n\nThough not necessary to the code working, it’s common, good practice to indent or tab the lines of code after the first line (counterexample below). Why? makes it easier to see each line\nThough not necessary to the code working, it’s common, good practice to put a line break after each + (counterexample below). Why? makes it easier to see each line!\n\nCode# Data on students in this class\nsurvey &lt;- read.csv(\"https://hash-mac.github.io/stat112site-s25/data/survey.csv\")\n\n# World Cup data\nworld_cup &lt;- read.csv(\"https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2022/2022-11-29/worldcups.csv\")\n\n\n\nCodehead(survey)\n\n         cafe_mac minutes_to_campus fav_temp_c       hangout\n1 mashed potatoes                 5         26 the mountains\n2        is tasty                 5         28        a city\n3          burger                 5         19      a forest\n4    caesar salad                12         18      a forest\n5       ice cream                 0         24 the mountains\n6           tofu                 10        -10 the mountains\n\n\n\nCodeggplot(survey, aes(x = minutes_to_campus)) +\n  geom_density() + \n  geom_density(color = \"purple\") +\nlabs(x = \"Minutes to Campus\", y = \"Number of students\")",
    "crumbs": [
      "In-class Activities",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>Univariate Viz</span>"
    ]
  },
  {
    "objectID": "ica/ica-bi.html",
    "href": "ica/ica-bi.html",
    "title": "\n12  Bivariate Viz\n",
    "section": "",
    "text": "Use this file for practice with the bivariate viz in-class activity. Refer to the class website for details.\n\nCode# Import data\nsurvey &lt;- read.csv(\"https://ajohns24.github.io/data/112/about_us_2024.csv\")\n\n# How many students have now filled out the survey? 28\nnrow(survey)\n\n[1] 28\n\nCode# What type of variables do we have? 4, ordinal and discrete\nstr(survey)\n\n'data.frame':   28 obs. of  4 variables:\n $ cafe_mac         : chr  \"Cheesecake\" \"Cheese pizza\" \"udon noodles\" \"egg rolls\" ...\n $ minutes_to_campus: int  15 10 4 7 5 35 5 15 7 20 ...\n $ fave_temp        : num  18 24 18 10 18 7 75 24 13 16 ...\n $ hangout          : chr  \"the mountains\" \"a beach\" \"the mountains\" \"a beach\" ...\n\n\n\nCode# Attach a package needed to use the ggplot function\nlibrary(tidyverse)\n\n# Make a ggplot\nggplot(survey, aes(x = hangout)) +\n  geom_bar() +\n labs(x = \"Places to hang out\", y = \"Number of students\")\n\n\n\n\n\n\n\n\nCodeggplot(survey, aes(x = fave_temp)) +\n geom_histogram(color = \"white\", fill = \"purple\", binwidth = 5) +\n labs(x = \"Favorite temp in c\", y = \"Number of students\")\n\n\n\n\n\n\n\n\naround 20 typical response, one outlier in very high area, maybe they thought they should answer in degrees farenheight\n\n\nCodeggplot(survey, aes(x = fave_temp)) +\n  geom_density(color = \"orange\") + \n  labs(x = \"Favorite temp in c\", y = \"Number of students\")\n\n\n\n\n\n\n\n\nCode# Load data\nelections &lt;- read.csv(\"https://mac-stat.github.io/data/election_2020_county.csv\")\n\n# Check it out\nhead(elections)\n\n  state_name state_abbr historical    county_name county_fips total_votes_20\n1    Alabama         AL        red Autauga County        1001          27770\n2    Alabama         AL        red Baldwin County        1003         109679\n3    Alabama         AL        red Barbour County        1005          10518\n4    Alabama         AL        red    Bibb County        1007           9595\n5    Alabama         AL        red  Blount County        1009          27588\n6    Alabama         AL        red Bullock County        1011           4613\n  repub_pct_20 dem_pct_20 winner_20 total_votes_16 repub_pct_16 dem_pct_16\n1        71.44      27.02     repub          24661        73.44      23.96\n2        76.17      22.41     repub          94090        77.35      19.57\n3        53.45      45.79     repub          10390        52.27      46.66\n4        78.43      20.70     repub           8748        76.97      21.42\n5        89.57       9.57     repub          25384        89.85       8.47\n6        24.84      74.70       dem           4701        24.23      75.09\n  winner_16 total_votes_12 repub_pct_12 dem_pct_12 winner_12 total_population\n1     repub          23909        72.63      26.58     repub            54907\n2     repub          84988        77.39      21.57     repub           187114\n3     repub          11459        48.34      51.25       dem            27321\n4     repub           8391        73.07      26.22     repub            22754\n5     repub          23980        86.49      12.35     repub            57623\n6       dem           5318        23.51      76.31       dem            10746\n  percent_white percent_black percent_asian percent_hispanic per_capita_income\n1            76            18             1                2             24571\n2            83             9             1                4             26766\n3            46            46             0                5             16829\n4            75            22             0                2             17427\n5            88             1             0                8             20730\n6            22            71             0                6             18628\n  median_rent median_age\n1         668       37.5\n2         693       41.5\n3         382       38.3\n4         351       39.4\n5         403       39.6\n6         276       39.6\n\n\nHow many, or roughly what percent, of the 3000+ counties did the Republican candidate win in 2020?\n\nTake a guess. 65%\nThen make a plot of the winner variable.\n\n\nCodelibrary(tidyverse)\nggplot(elections, aes(x = winner_20)) +\n  geom_bar()\n\n\n\n\n\n\nCodelabs(x = \"Party\", y = \"Number of Counties\")\n\n$x\n[1] \"Party\"\n\n$y\n[1] \"Number of Counties\"\n\nattr(,\"class\")\n[1] \"labels\"\n\n\n\nThen discuss what follow-up questions you might have (and that our data might help us answer). What is the population of each county? How many counties flipped in 2020?\n\n\n\nCodeggplot(elections, aes(x = repub_pct_20)) +\n geom_histogram(binwidth = 10) + \nlabs(x = \"Republican Support\", y = \"Number of Counties\")\n\n\n\n\n\n\n\nWhat follow-up questions do you have? How has this trend changed over time? What does the skewed data actually represent?\n\nCode# Set up the plotting frame\n# How does this differ than the frame for our histogram of repub_pct_20 alone? Both axes are numeric variables we're studying\nggplot(elections, aes(y = repub_pct_20, x = repub_pct_16))\n\n\n\n\n\n\n\n\nCode# Add a layer of points for each county\n# Take note of the geom! geom point\nggplot(elections, aes(y = repub_pct_20, x = repub_pct_16)) +\n  geom_point()\n\n\n\n\n\n\n\n\nCode# Change the shape of the points\n# What happens if you change the shape to another number? The shape of the points change\nggplot(elections, aes(y = repub_pct_20, x = repub_pct_16)) +\n  geom_point(shape = 3)\n\n\n\n\n\n\n\n\nCode# YOU TRY: Modify the code to make the points \"orange\"\n# NOTE: Try to anticipate if \"color\" or \"fill\" will be useful here. Then try both.\nggplot(elections, aes(y = repub_pct_20, x = repub_pct_16)) +\n  geom_point(color = \"red\", fill = \"blue\")\n\n\n\n\n\n\n\n\nCode# Add a layer that represents each county by the state it's in\n# Take note of the geom and the info it needs to run! text instead of point, label as changed to state abbr\nggplot(elections, aes(y = repub_pct_20, x = repub_pct_16)) +\n  geom_text(aes(label = state_abbr))\n\n\n\n\n\n\n\nSummarize the relationship between the Republican support in 2020 and 2016. Be sure to comment on:\n\nthe strength of the relationship (weak/moderate/strong) very strong relationship, it’s pretty linear\nthe direction of the relationship (positive/negative) positive slope\noutliers (in what state do counties deviate from the national trend? Any ideas why this might be the case?) I see a few in Texas, there’s been a shift in recent years in big cities to be more democratic, especially amongst the migrant population\n\n\nCodeggplot(elections, aes(y = repub_pct_20, x = repub_pct_16)) +\n  geom_smooth()\n\n\n\n\n\n\n\n\nCodeggplot(elections, aes(y = repub_pct_20, x = repub_pct_16)) +\n  geom_point() +\n  geom_smooth(method = \"lm\")\n\n\n\n\n\n\n\n\nCode# Scatterplot of repub_pct_20 vs median_rent\nggplot(elections, aes(y = repub_pct_20, x = median_rent)) +\n  geom_point()  +\n  geom_smooth()\n\n\n\n\n\n\nCode# Scatterplot of repub_pct_20 vs median_age\nggplot(elections, aes(y = repub_pct_20, x = median_age)) +\n  geom_point() +\n   geom_smooth()\n\n\n\n\n\n\n\n\nSummarize the relationship between these two variables and comment on which is the better predictor of repub_pct_20, median_rent or median_age. Median rent is a bit of a negative relationship, while median age is a bit more positive and linear. Based off of this, it seems like age is a better predictor\nExplain why a scatterplot might not be an effective visualization for exploring this relationship. (What questions does / doesn’t it help answer?) Doesn’t really show the patterns over time, makes it harder to see a clear relationship between all of the variables\n\n\nCodeggplot(elections, aes(y = repub_pct_20, x = historical)) +\n  geom_point()\n\n\n\n\n\n\n\n\nCode# Side-by-side violin plots\nggplot(elections, aes(y = repub_pct_20, x = historical)) +\n  geom_violin()\n\n\n\n\n\n\n\n\nCode# Side-by-side boxplots (defined below)\nggplot(elections, aes(y = repub_pct_20, x = historical)) +\n  geom_boxplot()\n\n\n\n\n\n\n\n\nSummarize what you’ve learned about the 2020 Republican county-level support within and between red/purple/blue states. In blue states, it’s a bit above 50, in purple states it’s around 60, and in red states it’s about 75. However, red states usually have more and lower outliers than in blue or purple states. Otherwise, most of the points are in a pretty similar place.\n\n\nCodeggplot(elections, aes(x = repub_pct_20)) +\n  geom_density()\n\n\n\n\n\n\n\n\nCode# Name two \"bad\" things about this plot. No axis labels, the colors aren't aligned with their labels\nggplot(elections, aes(x = repub_pct_20, fill = historical)) +\n  geom_density()\n\n\n\n\n\n\n\n\nCode# What does scale_fill_manual do? Allows labels to be filled with chosen colors, in the order of the variables\nggplot(elections, aes(x = repub_pct_20, fill = historical)) +\n  geom_density() +\n  scale_fill_manual(values = c(\"blue\", \"purple\", \"red\"))\n\n\n\n\n\n\n\n\nCode# What does alpha = 0.5 do? Makes the fill more transparent\n# Play around with different values of alpha, between 0 and 1\nggplot(elections, aes(x = repub_pct_20, fill = historical)) +\n  geom_density(alpha = 0.6) +\n  scale_fill_manual(values = c(\"blue\", \"purple\", \"red\"))\n\n\n\n\n\n\n\n\nCode# What does facet_wrap do?! Seperates the layers of graphs into three distinct graphs\nggplot(elections, aes(x = repub_pct_20, fill = historical)) +\n  geom_density() +\n  scale_fill_manual(values = c(\"blue\", \"purple\", \"red\")) +\n  facet_wrap(~ historical)\n\n\n\n\n\n\n\n\nCode# Let's try a similar grouping strategy with a histogram instead of density plot.\n# Why is this terrible? The layering of graphs is hard to see, the data doesn't seem to flow well, it's just a more visually clunky version of the density plot\nggplot(elections, aes(x = repub_pct_20, fill = historical)) +\n  geom_histogram(color = \"white\") +\n  scale_fill_manual(values = c(\"blue\", \"purple\", \"red\"))\n\n\n\n\n\n\n\nWe’ve now learned 3 (of many) ways to visualize the relationship between a quantitative and categorical variable: side-by-side violins, boxplots, and density plots.\n\nWhich do you like best? Box plots, it makes the data so easy to observe and comment on\nWhat is one pro of density plots relative to boxplots? It makes data easy to see in comparison to one another\nWhat is one con of density plots relative to boxplots? It only works if both values are quantitative\n\n\nCode# Plot 1: adjust this to recreate the top plot\nggplot(elections, aes(x = historical, fill = winner_20)) +\n  geom_bar()\n\n\n\n\n\n\n\n\nCode# Plot 2: adjust this to recreate the bottom plot\nggplot(elections, aes(x = winner_20)) +\n  geom_bar() +\n  facet_wrap(~ historical)\n\n\n\n\n\n\n\n\nCode# A stacked bar plot\n# How are the \"historical\" and \"winner_20\" variables mapped to the plot, i.e. what roles do they play? Fill lets us see the actual margins and comparisons of the data\nggplot(elections, aes(x = historical, , fill = winner_20)) +\n  geom_bar()\n\n\n\n\n\n\n\n\nName one pro and one con of using the “proportional bar plot” instead of one of the other three options. pro = easier to visually see the margins of the winners per party, con = it can make it a bit confusing when trying to explain how the historical margin is the x axis\nWhat’s your favorite bar plot from part and why? the facet wrap, I like how it compares each individual part of data, it makes it really easy for me to see the different patterns per state, and easier to focus on both each one by itself and in comparison to others\n\n\nCodeweather &lt;- read.csv(\"https://mac-stat.github.io/data/weather_3_locations.csv\")\n\n\n\nCode# How do 3pm temperatures (temp3pm) differ by location?\nggplot(weather, aes(x = temp3pm, fill = location)) +\n  geom_density(alpha = 0.6) \n\n\n\n\n\n\n\n\nCode# How might we predict the 3pm temperature (temp3pm) by the 9am temperature (temp9am)?\nggplot(weather, aes(y = temp3pm, x = temp9am)) +\n  geom_point() + \n  geom_smooth()\n\n\n\n\n\n\n\n\nCode# How do the number of rainy days (raintoday) differ by location?\nggplot(weather, aes(x = raintoday)) +\n  geom_bar() +\n  facet_wrap(~ location)",
    "crumbs": [
      "In-class Activities",
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>Bivariate Viz</span>"
    ]
  },
  {
    "objectID": "ica/ica-multi.html",
    "href": "ica/ica-multi.html",
    "title": "\n13  Mulivariate Viz\n",
    "section": "",
    "text": "Use this file for practice with the mulivariate viz in-class activity. Refer to the class website for details.\n\nCodelibrary(tidyverse)\n\n# Import data\nweather &lt;- read.csv(\"https://mac-stat.github.io/data/weather_3_locations.csv\") |&gt; \n  mutate(date = as.Date(date))  \n\n\n\nCode# Check out the first 6 rows\n# What are the units of observation? date, location, mintemp, maxtemp, rainfall, evaporation, sunshine, windgustdir, windgustspeed, winddir and speed, humidity, pressure, cloud, rain, risk\nhead(weather, 6)\n\n        date   location mintemp maxtemp rainfall evaporation sunshine\n1 2020-01-01 Wollongong    17.1    23.1        0          NA       NA\n2 2020-01-02 Wollongong    17.7    24.2        0          NA       NA\n3 2020-01-03 Wollongong    19.7    26.8        0          NA       NA\n4 2020-01-04 Wollongong    20.4    35.5        0          NA       NA\n5 2020-01-05 Wollongong    19.8    21.4        0          NA       NA\n6 2020-01-06 Wollongong    18.3    22.9        0          NA       NA\n  windgustdir windgustspeed winddir9am winddir3pm windspeed9am windspeed3pm\n1         SSW            39        SSW        SSE           20           15\n2         SSW            37          S        ENE           13           15\n3          NE            41        NNW        NNE            7           17\n4         SSW            78         NE        NNE           15           17\n5         SSW            57        SSW          S           31           35\n6          NE            35        ESE         NE           17           20\n  humidity9am humidity3pm pressure9am pressure3pm cloud9am cloud3pm temp9am\n1          69          64      1014.9      1014.0        8        1    19.1\n2          72          54      1020.1      1017.7        7        1    19.8\n3          72          71      1017.5      1013.0        6       NA    23.4\n4          77          69      1008.8      1003.9       NA       NA    24.5\n5          70          75      1018.9      1019.9       NA        7    20.7\n6          71          71      1021.2      1018.2       NA       NA    20.9\n  temp3pm raintoday risk_mm raintomorrow\n1    22.9        No     0.0           No\n2    23.6        No     0.0           No\n3    25.7        No     0.0           No\n4    26.7        No     0.0           No\n5    20.0        No     0.0           No\n6    22.6        No     0.8           No\n\n\n\nCode# How many data points do we have?  2367\nnrow(weather)\n\n[1] 2367\n\n\n\nCode# What type of variables do we have? categorical and numerical\nstr(weather)\n\n'data.frame':   2367 obs. of  24 variables:\n $ date         : Date, format: \"2020-01-01\" \"2020-01-02\" ...\n $ location     : chr  \"Wollongong\" \"Wollongong\" \"Wollongong\" \"Wollongong\" ...\n $ mintemp      : num  17.1 17.7 19.7 20.4 19.8 18.3 19.9 20.1 19.8 20.5 ...\n $ maxtemp      : num  23.1 24.2 26.8 35.5 21.4 22.9 25.6 23.2 23.1 25.4 ...\n $ rainfall     : num  0 0 0 0 0 0 0.8 1.6 0 0 ...\n $ evaporation  : num  NA NA NA NA NA NA NA NA NA NA ...\n $ sunshine     : num  NA NA NA NA NA NA NA NA NA NA ...\n $ windgustdir  : chr  \"SSW\" \"SSW\" \"NE\" \"SSW\" ...\n $ windgustspeed: int  39 37 41 78 57 35 44 41 39 56 ...\n $ winddir9am   : chr  \"SSW\" \"S\" \"NNW\" \"NE\" ...\n $ winddir3pm   : chr  \"SSE\" \"ENE\" \"NNE\" \"NNE\" ...\n $ windspeed9am : int  20 13 7 15 31 17 30 31 24 19 ...\n $ windspeed3pm : int  15 15 17 17 35 20 7 33 26 39 ...\n $ humidity9am  : int  69 72 72 77 70 71 76 77 76 79 ...\n $ humidity3pm  : int  64 54 71 69 75 71 72 76 79 76 ...\n $ pressure9am  : num  1015 1020 1018 1009 1019 ...\n $ pressure3pm  : num  1014 1018 1013 1004 1020 ...\n $ cloud9am     : int  8 7 6 NA NA NA NA 8 NA NA ...\n $ cloud3pm     : int  1 1 NA NA 7 NA NA NA NA NA ...\n $ temp9am      : num  19.1 19.8 23.4 24.5 20.7 20.9 22.9 21.3 21.2 23 ...\n $ temp3pm      : num  22.9 23.6 25.7 26.7 20 22.6 24.9 22.2 22.2 25.1 ...\n $ raintoday    : chr  \"No\" \"No\" \"No\" \"No\" ...\n $ risk_mm      : num  0 0 0 0 0 0.8 1.6 0 0 1 ...\n $ raintomorrow : chr  \"No\" \"No\" \"No\" \"No\" ...\n\n\nConstruct a plot that allows us to examine how temp3pm varies.\n\nCodelibrary(tidyverse)\nggplot(weather, aes(x = temp3pm)) +\n    geom_density()\n\n\n\n\n\n\n\n\nCode# Plot 1 (no facets & starting from a density plot of temp3pm)\nggplot(weather, aes(x = temp3pm, fill = location)) +\n  geom_density(alpha = 0.5)\n\n\n\n\n\n\n\n\nCode# Plot 2 (no facets or densities)\nggplot(weather, aes(y = temp3pm, x = location)) +\n  geom_boxplot()\n\n\n\n\n\n\n\n\nCode# Plot 3 (facets)\nggplot(weather, aes(x = temp3pm, fill = location)) +\n  geom_density(alpha = 0.5) +\n  facet_wrap(~ location)\n\n\n\n\n\n\n\n\nCode# Don't worry about the syntax (we'll learn it soon)\nwoll &lt;- weather |&gt;\n  filter(location == \"Wollongong\") |&gt; \n  mutate(date = as.Date(date))  \nlibrary(tidyverse)\n\n\n\nCode# How often does it raintoday?\n# Fill your geometric layer with the color blue.\nggplot(woll, aes(x = raintoday)) + \ngeom_bar(fill = \"blue\")\n\n\n\n\n\n\n\n\nCode# If it does raintoday, what does this tell us about raintomorrow? likeliness\n# Use your intuition first\nggplot(woll, aes(x = raintoday, fill = raintomorrow)) +\n    geom_bar()\n\n\n\n\n\n\n\n\nCode# Side-by-side bars\nggplot(woll, aes(x = raintoday, fill = raintomorrow)) + \n  geom_bar(position = \"dodge\")\n\n\n\n\n\n\n\n\nCode# Proportional bars\n# position = \"fill\" refers to filling the frame, nothing to do with the color-related fill\nggplot(woll, aes(x = raintoday, fill = raintomorrow)) + \n  geom_bar(position = \"fill\")\n\n\n\n\n\n\n\n\nCode# THINK: What variable goes on the y-axis?\n# For the curve, try adding span = 0.5 to tweak the curvature\n# Instead of a curve that captures the general TREND,\n# draw a line that illustrates the movement of RAW temperatures from day to day\n# NOTE: We haven't learned this geom yet! Guess.\nggplot(woll, aes(x = temp3pm, fill = date)) +\ngeom_density() \n\n\n\n\n\n\n\n\nCode# Import and check out data\neducation &lt;- read.csv(\"https://mac-stat.github.io/data/sat.csv\")\nhead(education)\n\n       State expend ratio salary frac verbal math  sat  fracCat\n1    Alabama  4.405  17.2 31.144    8    491  538 1029   (0,15]\n2     Alaska  8.963  17.6 47.951   47    445  489  934 (45,100]\n3    Arizona  4.778  19.3 32.175   27    448  496  944  (15,45]\n4   Arkansas  4.459  17.1 28.934    6    482  523 1005   (0,15]\n5 California  4.992  24.0 41.078   45    417  485  902  (15,45]\n6   Colorado  5.443  18.4 34.571   29    462  518  980  (15,45]\n\nCodelibrary(tidyverse)\n\n\n\nCodeggplot(education, aes(x=sat)) +\n    geom_histogram(binwidth = 5)\n\n\n\n\n\n\n\n\nSummarize your observations from the plot. Comment on the basics: range, typical outcomes, shape. (Any theories about what might explain this non-normal shape?) There seems to be no real average shape or concentration, and there’s quite a large range as well.\n\n\nCode# Construct a plot of sat vs expend\n# Include a \"best fit linear regression model\" (HINT: method = \"lm\")\nggplot(education, aes(y = sat, x = expend)) +\n  geom_point() +\n  geom_smooth(method = \"lm\")\n\n\n\n\n\n\n\n\nCode# Construct a plot of sat vs salary\n# Include a \"best fit linear regression model\" (HINT: method = \"lm\")\nggplot(education, aes(y = sat, x = salary)) +\n  geom_point() +\n  geom_smooth(method = \"lm\")\n\n\n\n\n\n\n\n\nWhat are the relationship trends between SAT scores and spending? Is there anything that surprises you? There’s almost a negative correlation, which really surprises me\n\n\nCode# Construct one visualization of the relationship of sat with salary and expend. HINT: Start with just 2 variables and tweak that code to add the third variable. Try out a few things!\nggplot(education, aes(y = sat, x = salary, color = expend)) +\n  geom_point() \n\n\n\n\n\n\n\n\nCodeggplot(education, aes(y = sat, x = salary, color = cut(expend, 3))) + \n  geom_point() + \n  geom_smooth(se = FALSE, method = \"lm\")\n\n\n\n\n\n\n\n\nDescribe the trivariate relationship between sat, salary, and expend. Low expend usually means low salary, and vice cersa, but a high salary and expend usually means a lower sat score, otherwise the sat scores are pretty scattered\n\n\nCode#Build a univariate viz of fracCat to better understand how many states fall into each category.\nggplot(education, aes(x=fracCat)) +\n    geom_bar() \n\n\n\n\n\n\n\n\nCode#Build 2 bivariate visualizations that demonstrate the relationship between sat and fracCat. What story does your graphic tell and why does this make contextual sense? This graph says that the more people take the sat in a state, usually their scores are worse than if a lot of students in that state take the sat. if a lower percentage take it, then maybe expend and resources are more focused on those few students?\nggplot(education, aes(x = sat, fill = fracCat)) +\n  geom_density(alpha = 0.5) \n\n\n\n\n\n\n\n\nCodeggplot(education, aes(x = fracCat, y = sat)) +\n  geom_boxplot()\n\n\n\n\n\n\n\n\nCode#Make a trivariate visualization that demonstrates the relationship of sat with expend AND fracCat. Highlight the differences in fracCat groups through color AND unique trend lines. What story does your graphic tell?\n# Does it still seem that SAT scores decrease as spending increases?\nggplot(education, aes(y = sat, x = expend, color = fracCat)) + \n  geom_point() + \n  geom_smooth(method = \"lm\")\n\n\n\n\n\n\n\n\nPutting all of this together, explain this example of Simpson’s Paradox. That is, why did it appear that SAT scores decrease as spending increases even though the opposite is true? the total spending doesn’t matter as much as the per student spending, if a small concentration of students is taking the sat, you can still spend less overall and then have per-student spending be more than spending more money for a lot more students.",
    "crumbs": [
      "In-class Activities",
      "<span class='chapter-number'>13</span>  <span class='chapter-title'>Mulivariate Viz</span>"
    ]
  },
  {
    "objectID": "ica/ica-spatial.html",
    "href": "ica/ica-spatial.html",
    "title": "\n14  Spatial Viz\n",
    "section": "",
    "text": "Use this file for practice with the spatial viz in-class activity. Refer to the class website for details.\n\nCodefave_places &lt;- read.csv(\"https://hash-mac.github.io/stat112site-s25/data/our_fave_places.csv\")\n\n# Check it out\nhead(fave_places)\n\n  latitude longitude\n1       59        18\n2       45       -93\n3       33      -117\n4       40       116\n5       40       106\n6       37      -122\n\n\n\nCode# Load the leaflet package\nlibrary(leaflet)\n\n# Just a plotting frame\nleaflet(data = fave_places)\n\n\n\n\n\n\nCode# Now what do we have?\nleaflet(data = fave_places) |&gt; \n  addTiles()\n\n\n\n\n\n\nCode# Now what do we have?\n# longitude and latitude refer to the variables in our data\nleaflet(data = fave_places) |&gt; \n  addTiles() |&gt; \n  addMarkers(lng = ~longitude, lat = ~latitude)\n\n\n\n\n\n\nCode# Since we named them \"longitude\" and \"latitude\", the function\n# automatically recognizes these variables. No need to write them!\nleaflet(data = fave_places) |&gt; \n  addTiles() |&gt; \n  addMarkers()\n\n\n\n\n\n\nCode# Load package needed to change color\nlibrary(gplots)\n\n# We can add colored circles instead of markers at each location\nleaflet(data = fave_places) |&gt; \n  addTiles() |&gt; \n  addCircles(color = col2hex(\"red\"))\n\n\n\n\n\n\nCode# We can change the background\n# Mark locations with yellow dots\n# And connect the dots, in their order in the dataset, with green lines\n# (These green lines don't mean anything here, but would if this were somebody's travel path!)\nleaflet(data = fave_places) |&gt;\n  addProviderTiles(\"USGS\") |&gt;\n  addCircles(weight = 10, opacity = 1, color = col2hex(\"yellow\")) |&gt;\n  addPolylines(\n    lng = ~longitude,\n    lat = ~latitude,\n    color = col2hex(\"green\")\n  )\n\n\n\n\n\n\nCodelibrary(tidyverse)\n# Import starbucks location data\nstarbucks &lt;- read.csv(\"https://mac-stat.github.io/data/starbucks.csv\")\n\n\n\nCode# Don't worry about the syntax\nstarbucks_mn &lt;- starbucks |&gt;   \n  filter(Country == \"US\", State.Province == \"MN\")\n\n\n\nCodeleaflet(data = starbucks_mn) |&gt; \n  addTiles() |&gt; \n  addMarkers()\n\n\n\n\n\n\nCodeggplot(starbucks, aes(y = Latitude, x = Longitude)) + \n  geom_point(alpha = 0.2, size = 0.2)\n\n\n\n\n\n\n\n\nCode# Load the package\nlibrary(rnaturalearth)\n\n# Get info about country boundaries across the world\n# in a \"sf\" or simple feature format\nworld_boundaries &lt;- ne_countries(returnclass = \"sf\")\n\n\n\nCode# What does this code produce?\n# What geom are we using for the point map?\nggplot(world_boundaries) + \n  geom_sf()\n\n\n\n\n\n\n\n\nCode# Load package needed to change map theme\nlibrary(mosaic)\n\n# Add a point for each Starbucks\n# NOTE: The Starbucks info is in our starbucks data, not world_boundaries\n# How does this change how we use geom_point?!\nggplot(world_boundaries) + \n  geom_sf() + \n  geom_point(\n    data = starbucks,\n    aes(x = Longitude, y = Latitude),\n    alpha = 0.3, size = 0.2, color = \"darkgreen\"\n  ) +\n  theme_map()\n\n\n\n\n\n\n\n\nSummarize what you learned about Starbucks from this map. They’re concentrated in the United States, Western Europe, and Eastern Asia\n\n\nCode# We'll learn this syntax soon! Don't worry about it now.\nstarbucks_cma &lt;- starbucks |&gt; \n  filter(Country %in% c('CA', 'MX', 'US'))\n\n\n\nCodecma_boundaries &lt;- ne_states(\n  country = c(\"canada\", \"mexico\", \"united states of america\"),\n  returnclass = \"sf\")\n\n\n\nCode# Just the boundaries\nlibrary(rnaturalearth)\nlibrary(rnaturalearthhires)\nlibrary(tidyverse)\nggplot(cma_boundaries) + \n  geom_sf()\n\n\n\n\n\n\n\n\nCode# Add the points\n# And zoom in\nggplot(cma_boundaries) + \n  geom_sf() + \n  geom_point(\n    data = starbucks_cma,\n    aes(x = Longitude, y = Latitude),\n    alpha = 0.3,\n    size = 0.2,\n    color = \"darkgreen\"\n  ) +\n  coord_sf(xlim = c(-179.14, -50)) +\n  theme_map()\n\n\n\n\n\n\n\n\nCodestarbucks_midwest &lt;- starbucks |&gt; \n  filter(State.Province %in% c(\"MN\", \"ND\", \"SD\", \"WI\"))\n\n\n\nCode# Load packages\nlibrary(sf)\nlibrary(maps)\n\n# Get the boundaries\nmidwest_boundaries &lt;- st_as_sf(\n  maps::map(\"county\",\n            region = c(\"minnesota\", \"wisconsin\", \"north dakota\", \"south dakota\"), \n            fill = TRUE, plot = FALSE))\n\n# Check it out\nhead(midwest_boundaries)\n\nSimple feature collection with 6 features and 1 field\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: -96.81268 ymin: 45.05167 xmax: -93.01397 ymax: 48.53526\nGeodetic CRS:  +proj=longlat +ellps=clrk66 +no_defs +type=crs\n                                     ID                           geom\nminnesota,aitkin       minnesota,aitkin MULTIPOLYGON (((-93.03689 4...\nminnesota,anoka         minnesota,anoka MULTIPOLYGON (((-93.51817 4...\nminnesota,becker       minnesota,becker MULTIPOLYGON (((-95.14537 4...\nminnesota,beltrami   minnesota,beltrami MULTIPOLYGON (((-95.58655 4...\nminnesota,benton       minnesota,benton MULTIPOLYGON (((-93.77027 4...\nminnesota,big stone minnesota,big stone MULTIPOLYGON (((-96.10794 4...\n\n\n\nCodeggplot(midwest_boundaries) + \n   geom_sf() + \n   geom_point(\n     data = starbucks_midwest,\n     aes(x = Longitude, y = Latitude),\n     alpha = 0.7,\n     size = 0.2, \n     color = 'darkgreen'\n   ) + \n   theme_map()\n\n\n\n\n\n\n\n\nCode# Point map (we made this earlier)\nggplot(cma_boundaries) + \n  geom_sf() + \n  geom_point(\n    data = starbucks_cma,\n    aes(x = Longitude, y = Latitude),\n    alpha = 0.3,\n    size = 0.2,\n    color = \"darkgreen\"\n  ) +\n  coord_sf(xlim = c(-179.14, -50), ylim = c(14.54, 83.11)) +\n  theme_map()\n\n\n\n\n\n\n\n\nCode# What changed in the plot?\n# What changed in our code?! geomdensity\nggplot(cma_boundaries) + \n  geom_sf() + \n  geom_density_2d(\n    data = starbucks_cma,\n    aes(x = Longitude, y = Latitude),\n    size = 0.2,\n    color = \"darkgreen\"\n  ) +\n  coord_sf(xlim = c(-179.14, -50), ylim = c(14.54, 83.11)) +\n  theme_map()\n\n\n\n\n\n\n\n\nCodeelections_by_state &lt;-  read.csv(\"https://mac-stat.github.io/data/election_2020_by_state.csv\")\nelections_by_counties &lt;- read.csv(\"https://mac-stat.github.io/data/election_2020_county.csv\")\n\n\n\nCode# Don't worry about the code!\n\nelections_by_state &lt;- elections_by_state |&gt; \n  filter(state_abbr != \"DC\") |&gt; \n  select(state_name, state_abbr, repub_pct_20) |&gt; \n  mutate(repub_20_categories = \n           cut(repub_pct_20, \n               breaks = seq(30, 70, by = 5), \n               labels = c(\"30-34\", \"35-39\", \"40-44\", \"45-49\",\n                          \"50-54\", \"55-59\", \"60-64\", \"65-70\"), \n               include.lowest = TRUE))\n\nelections_by_counties &lt;- elections_by_counties |&gt; \n  select(state_name, state_abbr, county_name, county_fips,\n          repub_pct_20, median_age, median_rent) |&gt; \n  mutate(repub_20_categories = \n           cut(repub_pct_20, \n               breaks = seq(0, 100, by = 10),\n               labels = c(\"0-9\", \"10-19\", \"20-29\", \"30-39\", \"40-49\",\n                          \"50-59\", \"60-69\", \"70-79\", \"80-89\", \"90-100\"),\n               include.lowest = TRUE))\n\n\n\nCode# Get the latitude and longitude coordinates of state boundaries\nstates_map &lt;- map_data(\"state\")\n\n# Check it out\nhead(states_map)\n\n       long      lat group order  region subregion\n1 -87.46201 30.38968     1     1 alabama      &lt;NA&gt;\n2 -87.48493 30.37249     1     2 alabama      &lt;NA&gt;\n3 -87.52503 30.37249     1     3 alabama      &lt;NA&gt;\n4 -87.53076 30.33239     1     4 alabama      &lt;NA&gt;\n5 -87.57087 30.32665     1     5 alabama      &lt;NA&gt;\n6 -87.58806 30.32665     1     6 alabama      &lt;NA&gt;\n\n\n\nCodehead(elections_by_state) \n\n   state_name state_abbr repub_pct_20 repub_20_categories\n1     alabama         AL        62.03               60-64\n2    arkansas         AR        62.40               60-64\n3     arizona         AZ        49.06               45-49\n4  california         CA        34.33               30-34\n5    colorado         CO        41.90               40-44\n6 connecticut         CT        39.21               35-39\n\n\n\nCode# Note where the dataset, elections_by_state, is used, in ggplot\n# Note where the background map, states_map, is used, in geommap\nggplot(elections_by_state, aes(map_id = state_name, fill = repub_pct_20)) +\n  geom_map(map = states_map) +\n  expand_limits(x = states_map$long, y = states_map$lat) +\n  theme_map() \n\n\n\n\n\n\n\n\nCode# Make it nicer!\nggplot(elections_by_state, aes(map_id = state_name, fill = repub_pct_20)) +\n  geom_map(map = states_map) +\n  expand_limits(x = states_map$long, y = states_map$lat) +\n  theme_map() + \n  scale_fill_gradientn(name = \"% Republican\", colors = c(\"blue\", \"purple\", \"red\"), values = scales::rescale(seq(0, 100, by = 5)))\n\n\n\n\n\n\n\n\nCodeggplot(elections_by_state, aes(map_id = state_name, fill = repub_20_categories)) +\n  geom_map(map = states_map) +\n  expand_limits(x = states_map$long, y = states_map$lat) +\n  theme_map()\n\n\n\n\n\n\n\n\nCode# Load package needed for refining color palette\nlibrary(RColorBrewer)\n\n# Now fix the colors\nggplot(elections_by_state, aes(map_id = state_name, fill = repub_20_categories)) +\n  geom_map(map = states_map) +\n  expand_limits(x = states_map$long, y = states_map$lat) +\n  theme_map() + \n  scale_fill_manual(values = rev(brewer.pal(8, \"RdBu\")), name = \"% Republican\")\n\n\n\n\n\n\n\n\nCode# Get only the starbucks data from the US\nstarbucks_us &lt;- starbucks |&gt; \n  filter(Country == \"US\")\n\n# Map it\nggplot(elections_by_state, aes(map_id = state_name, fill = repub_20_categories)) +\n  geom_map(map = states_map) +\n  geom_point(\n    data = starbucks_us,\n    aes(x = Longitude, y = Latitude),\n    size = 0.05,\n    alpha = 0.2,\n    inherit.aes = FALSE\n  ) +\n  expand_limits(x = states_map$long, y = states_map$lat) +\n  theme_map() + \n  scale_fill_manual(values = rev(brewer.pal(8, \"RdBu\")), name = \"% Republican\")\n\n\n\n\n\n\n\nWe used geom_sf() for point maps. What geom do we use for choropleth maps? geom_map\n\nCode# Get the latitude and longitude coordinates of county boundaries\nlibrary(socviz)\ndata(county_map) \n\n# Check it out\nhead(county_map)\n\n     long      lat order  hole piece            group    id\n1 1225889 -1275020     1 FALSE     1 0500000US01001.1 01001\n2 1235324 -1274008     2 FALSE     1 0500000US01001.1 01001\n3 1244873 -1272331     3 FALSE     1 0500000US01001.1 01001\n4 1244129 -1267515     4 FALSE     1 0500000US01001.1 01001\n5 1272010 -1262889     5 FALSE     1 0500000US01001.1 01001\n6 1276797 -1295514     6 FALSE     1 0500000US01001.1 01001\n\n\n\nCodehead(elections_by_counties)\n\n  state_name state_abbr    county_name county_fips repub_pct_20 median_age\n1    Alabama         AL Autauga County        1001        71.44       37.5\n2    Alabama         AL Baldwin County        1003        76.17       41.5\n3    Alabama         AL Barbour County        1005        53.45       38.3\n4    Alabama         AL    Bibb County        1007        78.43       39.4\n5    Alabama         AL  Blount County        1009        89.57       39.6\n6    Alabama         AL Bullock County        1011        24.84       39.6\n  median_rent repub_20_categories\n1         668               70-79\n2         693               70-79\n3         382               50-59\n4         351               70-79\n5         403               80-89\n6         276               20-29\n\n\n\nCode# Add 0's at the beginning of any fips_code that's fewer than 5 numbers long\n# Don't worry about the syntax\nelections_by_counties &lt;- elections_by_counties |&gt; \n  mutate(county_fips = as.character(county_fips)) |&gt; \n  mutate(county_fips = \n           ifelse(nchar(county_fips) == 4, paste0(\"0\", county_fips), county_fips))\n\n\n\nCodeggplot(elections_by_counties, aes(map_id = county_fips, fill = median_age)) +\n  geom_map(map = county_map) +\n  expand_limits(x = county_map$long, y = county_map$lat) +\n  theme_map() +\n  theme(legend.position = \"right\") + \n  coord_equal()",
    "crumbs": [
      "In-class Activities",
      "<span class='chapter-number'>14</span>  <span class='chapter-title'>Spatial Viz</span>"
    ]
  }
]